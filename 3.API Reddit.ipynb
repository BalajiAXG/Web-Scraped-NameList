{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d678a45f-fb20-4e2b-94ac-b3dab1dd0e6c",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.databricks.v1+bamboolib_hint": "{\"pd.DataFrames\": [], \"version\": \"0.0.1\"}",
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "It appears that you are using PRAW in an asynchronous environment.\nIt is strongly recommended to use Async PRAW: https://asyncpraw.readthedocs.io.\nSee https://praw.readthedocs.io/en/latest/getting_started/multiple_instances.html#discord-bots-and-asynchronous-environments for more info.\n\n"
     ]
    }
   ],
   "source": [
    "# !pip install praw\n",
    "import pandas as pd\n",
    "import praw\n",
    "\n",
    "reddit = praw.Reddit(\n",
    "    client_id=\"\",\n",
    "    client_secret=\"\",\n",
    "    user_agent=\"\"\n",
    ")\n",
    "subreddit = reddit.subreddit(\"python\")\n",
    "\n",
    "top_posts = subreddit.top(limit=10)\n",
    "new_posts = subreddit.new(limit=10)\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "post_info = []\n",
    "\n",
    "for post in top_posts:\n",
    "    post_info.append({\n",
    "        \"Title\": post.title,\n",
    "        \"ID\": post.id,\n",
    "        \"Author\": post.author,\n",
    "        \"URL\": post.url,\n",
    "        \"Score\": post.score,\n",
    "        \"Comments\": post.num_comments\n",
    "    })\n",
    "\n",
    "# Creating a DataFrame from the post data\n",
    "df = pd.DataFrame(post_info)\n",
    "\n",
    "# Print the DataFrame columns and values\n",
    "for index, row in df.iterrows():\n",
    "    # print(\"Post\", index + 1)\n",
    "    for column in df.columns:\n",
    "        pass\n",
    "        #print(f\"{column}: {row[column]}\")\n",
    "    pass\n",
    "df\n",
    "df.to_csv(\"reddit.csv\",index = False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ee820e92-c45f-4b08-9e0e-c8e69ace7d16",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Out[2]: [FileInfo(path='file:/databricks/driver/conf/', name='conf/', size=4096, modificationTime=1710926178381),\n FileInfo(path='file:/databricks/driver/preload_class.lst', name='preload_class.lst', size=1306936, modificationTime=1710926179741),\n FileInfo(path='file:/databricks/driver/azure/', name='azure/', size=4096, modificationTime=1710926179629),\n FileInfo(path='file:/databricks/driver/hadoop_accessed_config.lst', name='hadoop_accessed_config.lst', size=2755, modificationTime=1710926179661),\n FileInfo(path='file:/databricks/driver/ganglia/', name='ganglia/', size=4096, modificationTime=1710927913432),\n FileInfo(path='file:/databricks/driver/logs/', name='logs/', size=4096, modificationTime=1710927917792),\n FileInfo(path='file:/databricks/driver/eventlogs/', name='eventlogs/', size=4096, modificationTime=1710926432309),\n FileInfo(path='file:/databricks/driver/reddit.csv', name='reddit.csv', size=1552, modificationTime=1710928325008),\n FileInfo(path='file:/databricks/driver/all_posts_info.csv', name='all_posts_info.csv', size=2181, modificationTime=1710926948189),\n FileInfo(path='file:/databricks/driver/metastore_db/', name='metastore_db/', size=4096, modificationTime=1710926774881)]"
     ]
    }
   ],
   "source": [
    "dbutils.fs.ls('file:/databricks/driver')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5446258f-30c0-4aa6-a7a0-f87870083a89",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Out[3]: True"
     ]
    }
   ],
   "source": [
    "dbutils.fs.mv('file:/databricks/driver/reddit.csv', '/reddit.csv', recurse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "98369148-f371-4f2c-aa4c-2a1b3b2fa4e2",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>Title</th><th>ID</th><th>Author</th><th>URL</th><th>Score</th><th>Comments</th></tr></thead><tbody><tr><td>Lad wrote a Python script to download Alexa voice recordings, he didn't expect this email.</td><td>g53lxf</td><td>iEslam</td><td>https://i.redd.it/2s0dj8ob12u41.png</td><td>12342</td><td>133</td></tr><tr><td>This post has:</td><td>hoolsm</td><td>Krukerfluk</td><td>https://www.reddit.com/r/Python/comments/hoolsm/this_post_has/</td><td>9237</td><td>437</td></tr><tr><td>I redesign the Python logo to make it more modern</td><td>gftejm</td><td>jessjwilliamson</td><td>https://i.redd.it/rxezjyf4ojx41.png</td><td>7865</td><td>265</td></tr><tr><td>Automate the boring stuff with python - tinder</td><td>7kpme8</td><td>backprop88</td><td>https://gfycat.com/PointlessSimplisticAmericanquarterhorse</td><td>6730</td><td>325</td></tr><tr><td>Just finished programming and building my own smart mirror in python, wrote all of the code myself and implemented my own voice control and facial recognition features</td><td>dmkx8a</td><td>janky_british_gamer</td><td>https://i.redd.it/24ug9g82dju31.jpg</td><td>6611</td><td>468</td></tr><tr><td>I'm excited to share my first published book, Introduction to Python Programming for Business and Social Science Applications -- specifically geared towards students not specifically in computer science</td><td>irh8l0</td><td>paulkaefer</td><td>https://i.redd.it/ebmh8z3c8rm51.png</td><td>6499</td><td>249</td></tr><tr><td>Drawing Mona Lisa with 256 circles using evolution [Github repo in comments]</td><td>gn9add</td><td>Itwist101</td><td>https://v.redd.it/nyzyx7uyfwz41</td><td>5721</td><td>121</td></tr><tr><td>I made a simulation using Python in which a neural network learns to race</td><td>hqc7ol</td><td>atqm-</td><td>https://v.redd.it/bgmc6q20ela51</td><td>5689</td><td>212</td></tr><tr><td>Thanks to everyone’s advice, my mouse drawing algorithm has gotten much better and faster!</td><td>ghxqod</td><td>Nekose</td><td>https://v.redd.it/sktc30zom7y41</td><td>5549</td><td>203</td></tr><tr><td>Debugging Cheat Sheet</td><td>iehths</td><td>HotTeenBoy</td><td>https://i.redd.it/p1i8awsivji51.jpg</td><td>5447</td><td>112</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         "Lad wrote a Python script to download Alexa voice recordings, he didn't expect this email.",
         "g53lxf",
         "iEslam",
         "https://i.redd.it/2s0dj8ob12u41.png",
         12342,
         133
        ],
        [
         "This post has:",
         "hoolsm",
         "Krukerfluk",
         "https://www.reddit.com/r/Python/comments/hoolsm/this_post_has/",
         9237,
         437
        ],
        [
         "I redesign the Python logo to make it more modern",
         "gftejm",
         "jessjwilliamson",
         "https://i.redd.it/rxezjyf4ojx41.png",
         7865,
         265
        ],
        [
         "Automate the boring stuff with python - tinder",
         "7kpme8",
         "backprop88",
         "https://gfycat.com/PointlessSimplisticAmericanquarterhorse",
         6730,
         325
        ],
        [
         "Just finished programming and building my own smart mirror in python, wrote all of the code myself and implemented my own voice control and facial recognition features",
         "dmkx8a",
         "janky_british_gamer",
         "https://i.redd.it/24ug9g82dju31.jpg",
         6611,
         468
        ],
        [
         "I'm excited to share my first published book, Introduction to Python Programming for Business and Social Science Applications -- specifically geared towards students not specifically in computer science",
         "irh8l0",
         "paulkaefer",
         "https://i.redd.it/ebmh8z3c8rm51.png",
         6499,
         249
        ],
        [
         "Drawing Mona Lisa with 256 circles using evolution [Github repo in comments]",
         "gn9add",
         "Itwist101",
         "https://v.redd.it/nyzyx7uyfwz41",
         5721,
         121
        ],
        [
         "I made a simulation using Python in which a neural network learns to race",
         "hqc7ol",
         "atqm-",
         "https://v.redd.it/bgmc6q20ela51",
         5689,
         212
        ],
        [
         "Thanks to everyone’s advice, my mouse drawing algorithm has gotten much better and faster!",
         "ghxqod",
         "Nekose",
         "https://v.redd.it/sktc30zom7y41",
         5549,
         203
        ],
        [
         "Debugging Cheat Sheet",
         "iehths",
         "HotTeenBoy",
         "https://i.redd.it/p1i8awsivji51.jpg",
         5447,
         112
        ]
       ],
       "datasetInfos": [],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {},
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{}",
         "name": "Title",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "ID",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "Author",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "URL",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "Score",
         "type": "\"integer\""
        },
        {
         "metadata": "{}",
         "name": "Comments",
         "type": "\"integer\""
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "f=spark.read.csv(\"/reddit.csv\", header=True, inferSchema=True)\n",
    "display(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "95b21744-6886-4749-bb33-d4a83597a72c",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python interpreter will be restarted.\nRequirement already satisfied: snowflake-connector-python in /local_disk0/.ephemeral_nfs/envs/pythonEnv-95a889a1-b74a-4e07-bb54-274c135e3479/lib/python3.9/site-packages (3.7.1)\nRequirement already satisfied: asn1crypto<2.0.0,>0.24.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-95a889a1-b74a-4e07-bb54-274c135e3479/lib/python3.9/site-packages (from snowflake-connector-python) (1.5.1)\nRequirement already satisfied: pyjwt<3.0.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-95a889a1-b74a-4e07-bb54-274c135e3479/lib/python3.9/site-packages (from snowflake-connector-python) (2.8.0)\nRequirement already satisfied: platformdirs<4.0.0,>=2.6.0 in /usr/local/lib/python3.9/dist-packages (from snowflake-connector-python) (2.6.2)\nRequirement already satisfied: pyOpenSSL<25.0.0,>=16.2.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-95a889a1-b74a-4e07-bb54-274c135e3479/lib/python3.9/site-packages (from snowflake-connector-python) (24.1.0)\nRequirement already satisfied: filelock<4,>=3.5 in /usr/local/lib/python3.9/dist-packages (from snowflake-connector-python) (3.9.0)\nRequirement already satisfied: tomlkit in /local_disk0/.ephemeral_nfs/envs/pythonEnv-95a889a1-b74a-4e07-bb54-274c135e3479/lib/python3.9/site-packages (from snowflake-connector-python) (0.12.4)\nRequirement already satisfied: cryptography<43.0.0,>=3.1.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-95a889a1-b74a-4e07-bb54-274c135e3479/lib/python3.9/site-packages (from snowflake-connector-python) (42.0.5)\nRequirement already satisfied: charset-normalizer<4,>=2 in /databricks/python3/lib/python3.9/site-packages (from snowflake-connector-python) (2.0.4)\nRequirement already satisfied: pytz in /databricks/python3/lib/python3.9/site-packages (from snowflake-connector-python) (2021.3)\nRequirement already satisfied: certifi>=2017.4.17 in /databricks/python3/lib/python3.9/site-packages (from snowflake-connector-python) (2021.10.8)\nRequirement already satisfied: urllib3<2.0.0,>=1.21.1 in /databricks/python3/lib/python3.9/site-packages (from snowflake-connector-python) (1.26.9)\nRequirement already satisfied: idna<4,>=2.5 in /databricks/python3/lib/python3.9/site-packages (from snowflake-connector-python) (3.3)\nRequirement already satisfied: packaging in /databricks/python3/lib/python3.9/site-packages (from snowflake-connector-python) (21.3)\nRequirement already satisfied: typing-extensions<5,>=4.3 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-95a889a1-b74a-4e07-bb54-274c135e3479/lib/python3.9/site-packages (from snowflake-connector-python) (4.10.0)\nRequirement already satisfied: cffi<2.0.0,>=1.9 in /databricks/python3/lib/python3.9/site-packages (from snowflake-connector-python) (1.15.0)\nRequirement already satisfied: sortedcontainers>=2.4.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-95a889a1-b74a-4e07-bb54-274c135e3479/lib/python3.9/site-packages (from snowflake-connector-python) (2.4.0)\nRequirement already satisfied: requests<3.0.0 in /databricks/python3/lib/python3.9/site-packages (from snowflake-connector-python) (2.27.1)\nRequirement already satisfied: pycparser in /databricks/python3/lib/python3.9/site-packages (from cffi<2.0.0,>=1.9->snowflake-connector-python) (2.21)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /databricks/python3/lib/python3.9/site-packages (from packaging->snowflake-connector-python) (3.0.4)\nPython interpreter will be restarted.\n"
     ]
    }
   ],
   "source": [
    "# %pip install snowflake\n",
    "# %pip install snowflake-connector-python\n",
    "%pip install snowflake-connector-python\n",
    "import pandas as pd\n",
    "from pyspark.sql import SparkSession\n",
    "import snowflake.connector\n",
    "\n",
    "# Snowflake connection parameters\n",
    "account = 'My Account'\n",
    "user = 'My User Name'\n",
    "password = 'My Password'\n",
    "warehouse = 'My Warehouse Name'\n",
    "database = 'My Database Name'\n",
    "schema = 'My Schema Name'\n",
    "table_name = 'My Table Name'  # Table name without '.csv' suffix\n",
    "\n",
    "# Snowflake URL\n",
    "snowflake_url = ''\n",
    "\n",
    "# Load CSV into a Spark DataFrame\n",
    "file_path = \"/reddit.csv\"\n",
    "spark = SparkSession.builder.appName(\"SnowflakeIntegration\").getOrCreate()\n",
    "df = spark.read.csv(file_path, header=True, inferSchema=True)\n",
    "\n",
    "# Snowflake connection\n",
    "conn = snowflake.connector.connect(\n",
    "    user=user,\n",
    "    password=password,\n",
    "    account=account,\n",
    "    warehouse=warehouse,\n",
    "    database=database,\n",
    "    schema=schema,\n",
    "    sfURL=snowflake_url   # Include Snowflake URL\n",
    ")\n",
    "\n",
    "# Create cursor\n",
    "cur = conn.cursor()\n",
    "\n",
    "# Replace spaces and dots in table name\n",
    "table_name_sanitized = table_name.replace(' ', '_').replace('.', '_')\n",
    "\n",
    "# Create table in Snowflake with dynamically generated column definitions\n",
    "column_definitions = ', '.join([f'\"{col}\" STRING' for col in df.columns])\n",
    "cur.execute(f'CREATE OR REPLACE TABLE \"{schema}\".\"{table_name_sanitized}\" ({column_definitions})')\n",
    "\n",
    "# Write DataFrame to Snowflake table\n",
    "df.write.format(\"snowflake\") \\\n",
    "    .option(\"sfURL\", snowflake_url) \\\n",
    "    .option(\"sfUser\", user) \\\n",
    "    .option(\"sfPassword\", password) \\\n",
    "    .option(\"sfDatabase\", database) \\\n",
    "    .option(\"sfSchema\", schema) \\\n",
    "    .option(\"sfWarehouse\", warehouse) \\\n",
    "    .option(\"dbtable\", table_name_sanitized) \\\n",
    "    .mode(\"overwrite\") \\\n",
    "    .save()\n",
    "\n",
    "# Commit the transaction\n",
    "conn.commit()\n",
    "\n",
    "# Close cursor and connection\n",
    "cur.close()\n",
    "conn.close()\n"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "3.API Reddit",
   "widgets": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
